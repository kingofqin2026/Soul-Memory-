#!/usr/bin/env python3
"""
Soul Memory Semantic Deduplication v3.3
æ ¸å¿ƒæ”¹é€²ï¼šèªæ„ç›¸ä¼¼åº¦å»é‡ + MD5 å®Œå…¨åŒ¹é…é›™å±¤æ©Ÿåˆ¶
ç‰¹æ€§ï¼šä½¿ç”¨é€šç”¨è¡“èªï¼Œç„¡éœ€ç¡¬ç·¨ç¢¼ç”¨æˆ¶ç‰¹å®šå­—çœ¼
"""

import difflib
import hashlib
from typing import Dict, List, Tuple
from pathlib import Path


# ============================================
# èªæ„å»é‡é¡
# ============================================

class SemanticDedup:
    """
    èªæ„ç›¸ä¼¼åº¦å»é‡ï¼ˆé›™å±¤æ©Ÿåˆ¶ï¼‰
    
    ç¬¬ä¸€å±¤ï¼šMD5 å®Œå…¨åŒ¹é…ï¼ˆå¿«é€Ÿï¼‰
    ç¬¬äºŒå±¤ï¼šèªæ„ç›¸ä¼¼åº¦æª¢æŸ¥ï¼ˆç²¾ç¢ºï¼‰
    """
    
    def __init__(self, threshold=0.85, category_based=True):
        """
        åˆå§‹åŒ–å»é‡å™¨
        
        Args:
            threshold (float): èªæ„ç›¸ä¼¼åº¦é–¾å€¼ (0.0-1.0)
            category_based (bool): æ˜¯å¦åŸºæ–¼åˆ†é¡å»é‡ï¼ˆä¸åŒé¡åˆ¥ä¸æª¢æŸ¥ç›¸ä¼¼åº¦ï¼‰
        """
        self.threshold = threshold
        self.category_based = category_based
        
        # å·²ä¿å­˜çš„å…§å®¹ï¼ˆæŒ‰åˆ†é¡çµ„ç¹”ï¼‰
        self.saved_contents: Dict[str, List[str]] = {}
        
        # MD5 å“ˆå¸Œé›†åˆï¼ˆç¬¬ä¸€å±¤å»é‡ï¼‰
        self.saved_hashes: set = set()
    
    def get_content_hash(self, content: str) -> str:
        """
        è¨ˆç®—å…§å®¹ MD5 å“ˆå¸Œ
        
        Args:
            content (str): å…§å®¹
        
        Returns:
            str: MD5 å“ˆå¸Œï¼ˆ16 é€²åˆ¶ï¼‰
        """
        return hashlib.md5(content.encode('utf-8')).hexdigest()
    
    def is_duplicate_by_hash(self, content: str) -> bool:
        """
        ç¬¬ä¸€å±¤ï¼šMD5 å®Œå…¨åŒ¹é…æª¢æŸ¥
        
        Args:
            content (str): å…§å®¹
        
        Returns:
            bool: æ˜¯å¦é‡è¤‡
        """
        content_hash = self.get_content_hash(content)
        return content_hash in self.saved_hashes
    
    def is_duplicate_by_similarity(self, content: str, category: str = 'General') -> bool:
        """
        ç¬¬äºŒå±¤ï¼šèªæ„ç›¸ä¼¼åº¦æª¢æŸ¥
        
        Args:
            content (str): å…§å®¹
            category (str): åˆ†é¡æ¨™ç±¤
        
        Returns:
            bool: æ˜¯å¦èªæ„ç›¸ä¼¼
        """
        if not self.category_based:
            category = 'General'  # ä¸ä½¿ç”¨åˆ†é¡ï¼Œå…¨éƒ¨æª¢æŸ¥
        
        if category not in self.saved_contents:
            return False
        
        for saved in self.saved_contents[category]:
            # ä½¿ç”¨ difflib è¨ˆç®—åºåˆ—ç›¸ä¼¼åº¦
            similarity = difflib.SequenceMatcher(None, content, saved).ratio()
            
            if similarity > self.threshold:
                return True
        
        return False
    
    def is_duplicate(self, content: str, category: str = 'General') -> Tuple[bool, str]:
        """
        ç¶œåˆæª¢æŸ¥æ˜¯å¦é‡è¤‡ï¼ˆé›™å±¤æ©Ÿåˆ¶ï¼‰
        
        Args:
            content (str): å…§å®¹
            category (str): åˆ†é¡æ¨™ç±¤
        
        Returns:
            (bool, str): (æ˜¯å¦é‡è¤‡, å»é‡é¡å‹)
                          - 'exact': å®Œå…¨åŒ¹é…ï¼ˆMD5ï¼‰
                          - 'similar': èªæ„ç›¸ä¼¼
                          - 'unique': å”¯ä¸€
        """
        # ç¬¬ä¸€å±¤ï¼šMD5 å®Œå…¨åŒ¹é…
        if self.is_duplicate_by_hash(content):
            return True, 'exact'
        
        # ç¬¬äºŒå±¤ï¼šèªæ„ç›¸ä¼¼åº¦
        if self.is_duplicate_by_similarity(content, category):
            return True, 'similar'
        
        return False, 'unique'
    
    def save(self, content: str, category: str = 'General'):
        """
        ä¿å­˜å…§å®¹
        
        Args:
            content (str): å…§å®¹
            category (str): åˆ†é¡æ¨™ç±¤
        """
        # ä¿å­˜å“ˆå¸Œï¼ˆç¬¬ä¸€å±¤ï¼‰
        content_hash = self.get_content_hash(content)
        self.saved_hashes.add(content_hash)
        
        # ä¿å­˜å…§å®¹ï¼ˆç¬¬äºŒå±¤ï¼‰
        if self.category_based:
            if category not in self.saved_contents:
                self.saved_contents[category] = []
            self.saved_contents[category].append(content)
        else:
            if 'General' not in self.saved_contents:
                self.saved_contents['General'] = []
            self.saved_contents['General'].append(content)
    
    def get_stats(self) -> Dict:
        """
        çµ±è¨ˆä¿¡æ¯
        
        Returns:
            dict: çµ±è¨ˆæ•¸æ“š
        """
        total_contents = sum(len(contents) for contents in self.saved_contents.values())
        total_hashes = len(self.saved_hashes)
        categories = len(self.saved_contents)
        
        return {
            'total_contents': total_contents,
            'total_hashes': total_hashes,
            'categories': categories,
            'category_breakdown': {
                cat: len(contents) for cat, contents in self.saved_contents.items()
            }
        }


# ============================================
# æŒä¹…åŒ–æ”¯æŒ
# ============================================

class PersistentDedup(SemanticDedup):
    """æŒä¹…åŒ–å»é‡å™¨ï¼ˆå°‡ç‹€æ…‹ä¿å­˜åˆ°æ–‡ä»¶ï¼‰"""
    
    def __init__(self, storage_path: str, threshold=0.85, category_based=True):
        """
        åˆå§‹åŒ–æŒçºŒåŒ–å»é‡å™¨
        
        Args:
            storage_path (str): å­˜å„²è·¯å¾‘ï¼ˆJSON æ–‡ä»¶ï¼‰
            threshold (float): èªæ„ç›¸ä¼¼åº¦é–¾å€¼
            category_based (bool): æ˜¯å¦åŸºæ–¼åˆ†é¡
        """
        super().__init__(threshold, category_based)
        self.storage_path = Path(storage_path)
        
        # å¾æ–‡ä»¶åŠ è¼‰
        self._load_from_file()
    
    def _save_to_file(self):
        """ä¿å­˜åˆ°æ–‡ä»¶"""
        import json
        
        data = {
            'threshold': self.threshold,
            'category_based': self.category_based,
            'saved_hashes': list(self.saved_hashes),
            'saved_contents': self.saved_contents
        }
        
        self.storage_path.parent.mkdir(parents=True, exist_ok=True)
        
        with open(self.storage_path, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
    
    def _load_from_file(self):
        """å¾æ–‡ä»¶åŠ è¼‰"""
        import json
        
        if not self.storage_path.exists():
            return
        
        try:
            with open(self.storage_path, 'r', encoding='utf-8') as f:
                data = json.load(f)
            
            self.threshold = data.get('threshold', 0.85)
            self.category_based = data.get('category_based', True)
            self.saved_hashes = set(data.get('saved_hashes', []))
            self.saved_contents = data.get('saved_contents', {})
        except Exception as e:
            print(f"âš ï¸ åŠ è¼‰å»é‡è¨˜éŒ„å¤±æ•—: {e}")
    
    def save(self, content: str, category: str = 'General'):
        """ä¿å­˜å…§å®¹ä¸¦æŒä¹…åŒ–"""
        super().save(content, category)
        self._save_to_file()


# ============================================
# æ¸¬è©¦ä»£ç¢¼
# ============================================

if __name__ == '__main__':
    print("=" * 60)
    print("Soul Memory Semantic Dedup v3.3 - æ¸¬è©¦")
    print("=" * 60)
    
    # å‰µå»ºå»é‡å™¨
    dedup = SemanticDedup(threshold=0.85, category_based=True)
    
    # æ¸¬è©¦ç”¨ä¾‹
    test_contents = [
        ("éƒ¨ç½² framework åˆ° web_server", "Deployment"),
        ("éƒ¨ç½² framework åˆ° web_server", "Deployment"),  # å®Œå…¨ç›¸åŒ
        ("éƒ¨ç½² framework ç³»çµ±", "Deployment"),            # èªæ„ç›¸ä¼¼
        ("api_key é…ç½®å·²è¨­ç½®", "System"),                  # ä¸åŒåˆ†é¡
        ("api_key è¨­å®šå®Œæˆ", "System"),                   # èªæ„ç›¸ä¼¼ï¼ˆåŒåˆ†é¡ï¼‰
        ("api_key å·²ç¶“è¨­å®šå®Œç•¢", "System"),                # èªæ„ç›¸ä¼¼ï¼ˆåŒåˆ†é¡ï¼‰
    ]
    
    for i, (content, category) in enumerate(test_contents, 1):
        is_dup, dedup_type = dedup.is_duplicate(content, category)
        status = {
            'exact': 'ğŸ“¦ å®Œå…¨ç›¸åŒ',
            'similar': 'ğŸ”„ èªæ„ç›¸ä¼¼',
            'unique': 'âœ¨ å”¯ä¸€'
        }[dedup_type]
        
        print(f"\næ¸¬è©¦ {i}: [{category}]")
        print(f"  å…§å®¹: {content}")
        print(f"  ç‹€æ…‹: {status}")
        
        if not is_dup:
            dedup.save(content, category)
            print(f"  â†’ å·²ä¿å­˜")
        else:
            print(f"  â†’ å·²è·³é")
    
    # çµ±è¨ˆä¿¡æ¯
    print("\n" + "=" * 60)
    print("çµ±è¨ˆä¿¡æ¯")
    print("=" * 60)
    stats = dedup.get_stats()
    for key, value in stats.items():
        if key != 'category_breakdown':
            print(f"  {key}: {value}")
    
    print(f"\nåˆ†é¡è©³æƒ…:")
    for cat, count in stats['category_breakdown'].items():
        print(f"  {cat}: {count} æ¢")
