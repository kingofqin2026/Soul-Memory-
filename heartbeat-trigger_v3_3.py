#!/usr/bin/env python3
"""
Soul Memory Heartbeat Auto-Save Trigger v3.3
æ ¸å¿ƒæ”¹é€²ï¼š
1. åˆ†å±¤é—œéµè©å­—å…¸ï¼ˆé€šç”¨ Schemaï¼‰
2. èªæ„ç›¸ä¼¼åº¦å»é‡ï¼ˆé›™å±¤æ©Ÿåˆ¶ï¼‰
3. å¤šæ¨™ç±¤ç´¢å¼•ç³»çµ±
4. å„ªå…ˆç´šå‹•æ…‹èª¿æ•´
5. ä½¿ç”¨é€šç”¨è¡“èªï¼ˆç„¡ç¡¬ç·¨ç¢¼ç”¨æˆ¶å­—çœ¼ï¼‰
"""

import sys
import os
import json
import re
from pathlib import Path
from datetime import datetime, timedelta

SOUL_MEMORY_PATH = os.environ.get('SOUL_MEMORY_PATH', os.path.dirname(__file__))
sys.path.insert(0, SOUL_MEMORY_PATH)

# ============================================
# å°å…¥æ ¸å¿ƒæ¨¡çµ„
# ============================================
from core import SoulMemorySystem
from keyword_mapping_v3_3 import classify_content, get_priority_from_tags, KEYWORD_MAPPING
from semantic_dedup_v3_3 import PersistentDedup
from tag_index_v3_3 import TagIndex, update_tag_index

# ============================================
# è·¯å¾‘é…ç½®
# ============================================
SESSIONS_DIR = Path.home() / ".openclaw" / "agents" / "main" / "sessions"
SESSIONS_JSON = SESSIONS_DIR / "sessions.json"

# å»é‡è¨˜éŒ„å’Œæ¨™ç±¤ç´¢å¼•ï¼ˆv3.3ï¼‰
DATA_DIR = Path.home() / ".openclaw" / "workspace" / "soul-memory" / "data"
DEDUP_FILE = DATA_DIR / "dedup.json"
TAG_INDEX_FILE = DATA_DIR / "tag_index.json"

# ============================================
# Session æ•¸æ“šè®€å–
# ============================================

def get_active_session_id() -> str:
    """ç²å–ç•¶å‰ active session çš„ ID"""
    try:
        with open(SESSIONS_JSON, 'r', encoding='utf-8') as f:
            sessions = json.load(f)
        
        best_session = None
        best_time = 0
        
        for key, data in sessions.items():
            if isinstance(data, dict) and 'updatedAt' in data:
                if data['updatedAt'] > best_time:
                    best_time = data['updatedAt']
                    best_session = data.get('sessionId', key)
        
        return best_session
    except Exception as e:
        print(f"âš ï¸ ç„¡æ³•è®€å– sessions.json: {e}")
        return None


def read_session_messages(session_id: str, hours: int = 1) -> list:
    """è®€å– session å°è©±å…§å®¹ï¼ˆæœ€è¿‘ N å°æ™‚ï¼‰"""
    session_file = SESSIONS_DIR / f"{session_id}.jsonl"
    
    if not session_file.exists():
        print(f"âš ï¸ Session æª”æ¡ˆä¸å­˜åœ¨: {session_file}")
        return []
    
    messages = []
    cutoff_time = datetime.now() - timedelta(hours=hours)
    
    try:
        with open(session_file, 'r', encoding='utf-8') as f:
            for line in f:
                if not line.strip():
                    continue
                
                try:
                    entry = json.loads(line)
                    
                    if entry.get('type') != 'message':
                        continue
                    
                    timestamp_str = entry.get('timestamp', '')
                    if not timestamp_str:
                        continue
                    
                    try:
                        msg_time = datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
                        msg_time = msg_time.replace(tzinfo=None)
                    except:
                        continue
                    
                    if msg_time < cutoff_time:
                        continue
                    
                    message = entry.get('message', {})
                    role = message.get('role', '')
                    content = message.get('content', [])
                    
                    # æå–æ–‡æœ¬å…§å®¹
                    text_content = ''
                    if isinstance(content, list):
                        for item in content:
                            if isinstance(item, dict) and item.get('type') == 'text':
                                text_content += item.get('text', '')
                    
                    if text_content.strip():
                        messages.append({
                            'time': msg_time,
                            'role': role,
                            'content': text_content.strip()
                        })
                        
                except json.JSONDecodeError:
                    continue
                    
    except Exception as e:
        print(f"âš ï¸ è®€å– session æª”æ¡ˆéŒ¯èª¤: {e}")
    
    return messages


# ============================================
# å…§å®¹è­˜åˆ¥ï¼ˆv3.3 æ”¹é€²ï¼‰
# ============================================

def identify_important_content(messages: list) -> list:
    """
    è­˜åˆ¥é‡è¦å…§å®¹ï¼ˆv3.3 - ä½¿ç”¨åˆ†å±¤é—œéµè©ï¼‰
    
    Args:
        messages: æ¶ˆæ¯åˆ—è¡¨
    
    Returns:
        list: é‡è¦å…§å®¹åˆ—è¡¨ [{time, content, priority, tags}, ...]
    """
    important = []
    
    for msg in messages:
        content = msg['content']
        
        # æ’é™¤è¦å‰‡ï¼ˆv3.3 åŸºç¤ï¼‰
        if len(content) < 30:
            continue
        
        if 'HEARTBEAT.md' in content or 'Read HEARTBEAT.md' in content:
            continue
        
        # v3.3: ä½¿ç”¨åˆ†å±¤é—œéµè©å­—å…¸
        tags = classify_content(content)
        priority = get_priority_from_tags(tags)
        
        # é•·å…§å®¹æå‡å„ªå…ˆç´š
        if len(content) > 200 and priority == 'I':
            priority = 'C'
        
        # AI å›æ‡‰ä¸”é‡è¦
        if msg['role'] == 'assistant' and (tags or len(content) > 100):
            important.append({
                'time': msg['time'],
                'content': content,
                'priority': priority,
                'tags': tags
            })
    
    return important


# ============================================
# ä¿å­˜åˆ° Daily Fileï¼ˆv3.3 æ”¯æŒæ¨™ç±¤ï¼‰
# ============================================

def save_to_daily_file(content: str, priority: str, tags: list = None) -> str:
    """
    ä¿å­˜åˆ° daily fileï¼ˆæ”¯æŒæ¨™ç±¤ï¼‰
    
    Args:
        content: å…§å®¹
        priority: å„ªå…ˆç´š [C/I/N]
        tags: [(tag, weight), ...]
    
    Returns:
        str: daily file è·¯å¾‘
    """
    today = datetime.now().strftime('%Y-%m-%d')
    daily_dir = Path.home() / ".openclaw" / "workspace" / "memory"
    daily_file = daily_dir / f"{today}.md"
    
    daily_dir.mkdir(parents=True, exist_ok=True)
    
    timestamp = datetime.now().strftime('%H:%M')
    header = "\n\n" + "-" * 50 + "\n"
    
    # v3.3: æ·»åŠ æ¨™ç±¤è¡Œ
    if tags:
        tag_str = ', '.join([f"{t[0]}({t[1]})" for t in tags[:3]])  # åªé¡¯ç¤ºå‰ 3 å€‹
        header += f"**æ¨™ç±¤**: {tag_str}\n"
    
    header += f"## [{priority}] {timestamp} - Heartbeat è‡ªå‹•æå–\n"
    header += f"**ä¾†æº**ï¼šSession å°è©±å›é¡§\n"
    header += f"**æ™‚å€**ï¼šUTC\n\n"
    
    with open(daily_file, 'a', encoding='utf-8') as f:
        f.write(header)
        f.write(content)
        f.write('\n')
    
    return str(daily_file)


# ============================================
# Daily File çµ±è¨ˆ
# ============================================

def check_daily_memory() -> tuple:
    """æª¢æŸ¥ä»Šæ—¥è¨˜æ†¶æª”æ¡ˆ"""
    today = datetime.now().strftime('%Y-%m-%d')
    daily_file = Path.home() / ".openclaw" / "workspace" / "memory" / f"{today}.md"
    
    if daily_file.exists():
        with open(daily_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # è¨ˆç®—å„é¡æ¨™è¨˜æ•¸é‡
        auto_save_count = content.count('[Auto-Save]')
        heartbeat_extract = content.count('## [C]') + content.count('## [I]') - auto_save_count
        
        return auto_save_count, heartbeat_extract
    
    return 0, 0


# ============================================
# ä¸»å‡½æ•¸
# ============================================

def main():
    """Heartbeat æª¢æŸ¥é»ï¼ˆv3.3ï¼‰"""
    print(f"ğŸ§  åˆå§‹åŒ– Soul Memory System v3.3...")
    system = SoulMemorySystem()
    system.initialize()
    print(f"âœ… è¨˜æ†¶ç³»çµ±å°±ç·’")
    
    # v3.3: åˆå§‹åŒ–æ–°çµ„ä»¶
    print(f"ğŸ”§ åˆå§‹åŒ–å»é‡ç³»çµ±...")
    dedup = PersistentDedup(str(DEDUP_FILE), threshold=0.85, category_based=True)
    
    print(f"ğŸ·ï¸  åˆå§‹åŒ–æ¨™ç±¤ç´¢å¼•...")
    tag_idx = TagIndex(str(TAG_INDEX_FILE))
    
    # æª¢æŸ¥ç¾æœ‰è¨˜æ†¶
    auto_save_count, heartbeat_extract_count = check_daily_memory()
    
    print(f"\nğŸ©º Heartbeat è¨˜æ†¶æª¢æŸ¥ ({datetime.now().strftime('%Y-%m-%d %H:%M:%S')} UTC)")
    print(f"- [Auto-Save] æ¢ç›®ï¼š{auto_save_count} æ¢")
    print(f"- [Heartbeat æå–] æ¢ç›®ï¼š{heartbeat_extract_count} æ¢")
    
    # ä¸»å‹•æå–å°è©±
    print(f"\nğŸ” é–‹å§‹ä¸»å‹•æå–å°è©±...")
    
    session_id = get_active_session_id()
    if not session_id:
        print("âš ï¸ ç„¡æ³•ç²å– session IDï¼Œè·³éå°è©±æå–")
        print(f"\nğŸ“Š æœ€çµ‚ç‹€æ…‹: âŒ ç„¡æ–°è¨˜æ†¶éœ€è¦ä¿å­˜")
        return
    
    print(f"ğŸ“‹ ç•¶å‰ Session: {session_id[:8]}...")
    
    # è®€å–æœ€è¿‘ 1 å°æ™‚çš„å°è©±
    messages = read_session_messages(session_id, hours=1)
    print(f"ğŸ“ æ‰¾åˆ° {len(messages)} æ¢ recent æ¶ˆæ¯")
    
    # è­˜åˆ¥é‡è¦å…§å®¹
    important = identify_important_content(messages)
    print(f"â­ è­˜åˆ¥å‡º {len(important)} æ¢é‡è¦å…§å®¹")
    
    # çµ±è¨ˆå»é‡çµ±è¨ˆ
    saved_count = 0
    skipped_exact = 0
    skipped_similar = 0
    
    for item in important:
        # v3.3: ç²å–åˆ†é¡
        tags = item['tags']
        if tags:
            category = tags[0][0]  # ä½¿ç”¨ç¬¬ä¸€å€‹æ¨™ç±¤ä½œç‚ºåˆ†é¡
        else:
            category = 'General'
        
        # v3.3: é›™å±¤å»é‡æª¢æŸ¥
        is_dup, dedup_type = dedup.is_duplicate(item['content'], category)
        
        if is_dup:
            if dedup_type == 'exact':
                skipped_exact += 1
                print(f"  ğŸ“¦ è·³éå®Œå…¨ç›¸åŒ [{item['priority']}] - {len(item['content'])} å­—")
            else:
                skipped_similar += 1
                print(f"  ğŸ”„ è·³éèªæ„ç›¸ä¼¼ [{item['priority']}/{category}] - {len(item['content'])} å­—")
            continue
        
        # v3.3: ä¿å­˜å…§å®¹ + æ¨™ç±¤
        daily_file = save_to_daily_file(item['content'], item['priority'], tags)
        
        # ä¿å­˜åˆ°å»é‡ç³»çµ±
        dedup.save(item['content'], category)
        
        # v3.3: æ›´æ–°æ¨™ç±¤ç´¢å¼•
        update_tag_index(
            item['content'],
            item['priority'],
            tags,
            daily_file,
            tag_idx
        )
        
        saved_count += 1
        tag_display = ', '.join([t[0] for t in tags[:2]]) if tags else 'ç„¡'
        print(f"  âœ… ä¿å­˜ [{item['priority']}] {saved_count}/{len(important)} - {len(item['content'])} å­— (æ¨™ç±¤: {tag_display})")
    
    # æœ€çµ‚å ±å‘Š
    print(f"\nğŸ“Š æœ€çµ‚ç‹€æ…‹:")
    new_auto_save, new_heartbeat = check_daily_memory()
    
    if new_auto_save > auto_save_count or new_heartbeat > heartbeat_extract_count:
        print(f"âœ… æ–°å¢è¨˜æ†¶å·²ä¿å­˜")
        print(f"   - æ–°å¢: {saved_count} æ¢")
        print(f"   - è·³éå®Œå…¨ç›¸åŒ: {skipped_exact} æ¢")
        print(f"   - è·³éèªæ„ç›¸ä¼¼: {skipped_similar} æ¢")
        print(f"   â†³ ä¿å­˜è‡³ memory/{datetime.now().strftime('%Y-%m-%d')}.md")
        
        # v3.3: é¡¯ç¤ºæ¨™ç±¤çµ±è¨ˆ
        tag_stats = tag_idx.get_stats()
        print(f"\nğŸ·ï¸  æ¨™ç±¤ç´¢å¼•çµ±è¨ˆ:")
        print(f"   - ç¸½æ¨™ç±¤æ•¸: {tag_stats['total_tags']}")
        print(f"   - ç¸½ç´¢å¼•æ¢ç›®: {tag_stats['total_entries']}")
        
        if tag_stats['top_tags']:
            print(f"\n   ç†±é–€æ¨™ç±¤:")
            for tag, count in tag_stats['top_tags'][:3]:
                print(f"   - {tag}: {count}")
    else:
        print("âŒ ç„¡æ–°è¨˜æ†¶éœ€è¦ä¿å­˜")


if __name__ == '__main__':
    main()
